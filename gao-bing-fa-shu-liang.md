并发数VS请求数
并发连接数指的是客户端向服务器发起请求，并建立了TCP连接。每秒钟服务器链接的总TCP数量，就是并发连接数


请求数指的是客户端在建立完连接后，向http服务发出GET/POST/HEAD数据包，服务器返回了请求结果后有两种情况：

http数据包头包含Close字样，关闭本次TCP连接；

http数据包头包含Keep-Alive字样，本次连接不关闭，可继续通过该连接继续向http服务发送请求，用于减少TCP并发连接数。





大型系统、业务量非常高、硬件配置足够多的情况下，5000用户并发就足够了；
对于中小型系统，1000用户并发就足够了，700-800也够了


Tomcat 250-300 勉强支撑，拥有 250 个以上并发，应考虑应用服务器的集群
Tomcat 默认配置的最大请求数是 150，也就是说同时支持 150 个并发，当然了，也可以将其改大。
当某个应用拥有 250 个以上并发的时候，应考虑应用服务器的集群。
具体能承载多少并发，需要看硬件的配置，CPU 越多性能越高，分配给 JVM 的内存越多性能也就越高，但也会加重 GC 的负担。

操作系统对于进程中的线程数有一定的限制：
Windows 每个进程中的线程数不允许超过 2000
Linux 每个进程中的线程数不允许超过 1000


maxThreads="1000" 最大并发数 
minSpareThreads="100"///初始化时创建的线程数
maxSpareThreads="500"///一旦创建的线程超过这个值，Tomcat就会关闭不再需要的socket线程。
acceptCount="700"// 指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理

http://blog.51cto.com/53cto/1715678
http://blog.51cto.com/lookingdream/1889636
https://my.oschina.net/zfscofield/blog/1629215

好机器的 Tomcat 跑 500 并发还是能做到的。那么每秒钟处理 3 万个请求，只需要一个线程每秒钟能处理 60 个请求。16ms 处理一个请求就行

由于互联网有一个传说中的“3秒定律”，可能当下更多的网站技术指标要求1.5秒以内加载整页，或者至少可以达到阅读的标准。如果要较真什么“同时在线”